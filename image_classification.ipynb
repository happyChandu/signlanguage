{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Project setup"
      ],
      "metadata": {
        "id": "p5R5wj-bqpwe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUIPYGlImdhe"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login\n",
        "from wandb.keras import WandbCallback\n",
        "import wandb\n",
        "wandb.init(project=\"slc0\")"
      ],
      "metadata": {
        "id": "sFOVX3p1DKF6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "c70614e2-1af0-4b34-b731-0a71a0c5a33a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchandu_\u001b[0m (\u001b[33mc01\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230122_141057-0v1vylia</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/c01/slc0/runs/0v1vylia\" target=\"_blank\">soft-lake-1</a></strong> to <a href=\"https://wandb.ai/c01/slc0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href=\"https://wandb.ai/c01/slc0\" target=\"_blank\">https://wandb.ai/c01/slc0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href=\"https://wandb.ai/c01/slc0/runs/0v1vylia\" target=\"_blank\">https://wandb.ai/c01/slc0/runs/0v1vylia</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/c01/slc0/runs/0v1vylia?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fd6a9f42eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mOgToCGonCg",
        "outputId": "7bbb3c03-e570-4b97-995a-4caa81294d8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-1aa66ed7-782c-7749-b791-c3c61d1c420a)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu_rgf2PplKI",
        "outputId": "21f70cc5-07dd-45fd-f5f9-102fe0845e43"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.global_policy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v8leRaepr8x",
        "outputId": "4d1f50ea-8f51-4283-fcfd-4aa349d35cc9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Policy \"float32\">"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision.set_global_policy(policy=\"mixed_float16\")\n",
        "mixed_precision.global_policy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5va-8XnqAIQ",
        "outputId": "a1ed94cb-67c2-476f-8fbb-24a2961692f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Policy \"mixed_float16\">"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Data"
      ],
      "metadata": {
        "id": "vW1aPsSIqH2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile \n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/tensorflowCNN/dataset/archive.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "97NAZOQOrg4J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"asl_alphabet_train/asl_alphabet_train\",\n",
        "    label_mode=\"categorical\", \n",
        "    image_size=(200, 200),\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42\n",
        ")\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"asl_alphabet_train/asl_alphabet_train\",\n",
        "    label_mode=\"categorical\", \n",
        "    image_size=(200, 200),\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bxq-R60s1es",
        "outputId": "604e7f6d-80f3-4351-a796-2642b0014026"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 87000 files belonging to 29 classes.\n",
            "Using 69600 files for training.\n",
            "Found 87000 files belonging to 29 classes.\n",
            "Using 17400 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling"
      ],
      "metadata": {
        "id": "cVelvDjlxK7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model_0(ANN)"
      ],
      "metadata": {
        "id": "VgJm07k3xuG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model_0 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.LayerNormalization(axis=1),\n",
        "    tf.keras.layers.Dense(300, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(300, activation=tf.keras.activations.relu), \n",
        "    tf.keras.layers.Dense(29), \n",
        "    tf.keras.layers.Activation(tf.keras.activations.softmax, dtype=tf.float32)\n",
        "])\n",
        "model_0.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_0 = model_0.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_0\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPzML99sxfXU",
        "outputId": "8cd9089a-9a18-4641-be3f-83ed7231c5de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 62s 27ms/step - loss: 3.6438 - accuracy: 0.1823 - val_loss: 2.7951 - val_accuracy: 0.1753\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 56s 26ms/step - loss: 2.5378 - accuracy: 0.2199 - val_loss: 2.2436 - val_accuracy: 0.2684\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 58s 27ms/step - loss: 2.0334 - accuracy: 0.3229 - val_loss: 1.7103 - val_accuracy: 0.3886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_1 (adding more layers to model_0)"
      ],
      "metadata": {
        "id": "hjMowPBD2og2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.LayerNormalization(),\n",
        "    tf.keras.layers.Dense(1000, activation=tf.keras.activations.relu), \n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(29), \n",
        "    tf.keras.layers.Activation(tf.keras.activations.softmax, dtype=tf.float32)\n",
        "])\n",
        "model_1.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_1 = model_1.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_1\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuokMQXH0lGF",
        "outputId": "c9ceaa6a-547b-45e9-e2c1-d328fa361f41"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 104s 47ms/step - loss: 3.2205 - accuracy: 0.2892 - val_loss: 1.8313 - val_accuracy: 0.4095\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 105s 48ms/step - loss: 1.3205 - accuracy: 0.5605 - val_loss: 1.0822 - val_accuracy: 0.6317\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 103s 47ms/step - loss: 0.9648 - accuracy: 0.6898 - val_loss: 0.8402 - val_accuracy: 0.7282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_2(tweaking activation function and optimizer)"
      ],
      "metadata": {
        "id": "and21Q1q4Yqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model_2_1(with tanh activation function and SGD optimizer)"
      ],
      "metadata": {
        "id": "bYBpEX5s5pR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.LayerNormalization(),\n",
        "    tf.keras.layers.Dense(1000, activation=tf.keras.activations.tanh), \n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.tanh),\n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.tanh),\n",
        "    tf.keras.layers.Dense(29), \n",
        "    tf.keras.layers.Activation(tf.keras.activations.softmax, dtype=tf.float32)\n",
        "])\n",
        "model_2_1.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.SGD()\n",
        ")\n",
        "history_2_1 = model_2_1.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_2\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-WQHbUR4r9i",
        "outputId": "c766ea0d-ab96-4781-9983-b8d41f2e2123"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 76s 35ms/step - loss: 1.4835 - accuracy: 0.5598 - val_loss: 0.9572 - val_accuracy: 0.7034\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 75s 35ms/step - loss: 0.8518 - accuracy: 0.7369 - val_loss: 0.8467 - val_accuracy: 0.7275\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 75s 34ms/step - loss: 0.7562 - accuracy: 0.7582 - val_loss: 0.8394 - val_accuracy: 0.7321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model_2_2(with tanh activation function and Adam optimizer)"
      ],
      "metadata": {
        "id": "sfEFO0t264en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.LayerNormalization(),\n",
        "    tf.keras.layers.Dense(1000, activation=tf.keras.activations.tanh), \n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.tanh),\n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.tanh),\n",
        "    tf.keras.layers.Dense(29), \n",
        "    tf.keras.layers.Activation(tf.keras.activations.softmax, dtype=tf.float32)\n",
        "])\n",
        "model_2_2.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_2_2 = model_2_2.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_2_2\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbbjWRwM5kW1",
        "outputId": "6d9e373d-9b53-4538-f319-c5faa3d14c0f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 106s 48ms/step - loss: 2.5164 - accuracy: 0.2391 - val_loss: 2.1398 - val_accuracy: 0.3288\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 102s 47ms/step - loss: 2.0051 - accuracy: 0.3650 - val_loss: 1.8985 - val_accuracy: 0.3902\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 105s 48ms/step - loss: 1.7434 - accuracy: 0.4321 - val_loss: 1.6425 - val_accuracy: 0.4724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model_2_3(with sigmoid activation function and Adam optimizer)"
      ],
      "metadata": {
        "id": "8EyK5KnX7Xi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.LayerNormalization(),\n",
        "    tf.keras.layers.Dense(1000, activation=tf.keras.activations.sigmoid), \n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.sigmoid),\n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.sigmoid),\n",
        "    tf.keras.layers.Dense(29), \n",
        "    tf.keras.layers.Activation(tf.keras.activations.softmax, dtype=tf.float32)\n",
        "])\n",
        "model_2_3.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_2_3 = model_2_3.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_2_3\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97-ULP756qEY",
        "outputId": "eee14944-e4d9-4af0-b5d4-a18894300159"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 105s 48ms/step - loss: 2.4806 - accuracy: 0.2290 - val_loss: 2.0308 - val_accuracy: 0.3309\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 104s 48ms/step - loss: 1.7395 - accuracy: 0.4253 - val_loss: 1.4625 - val_accuracy: 0.5000\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 104s 48ms/step - loss: 1.3430 - accuracy: 0.5459 - val_loss: 1.1863 - val_accuracy: 0.5995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_3(add conv2D layers to model_1)\n",
        "* without normalization"
      ],
      "metadata": {
        "id": "qLG56K6O-oig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = tf.keras.Sequential([\n",
        "    # tf.keras.layers.Rescaling(1/255.),\n",
        "    tf.keras.layers.Conv2D(10, 3, 1,\n",
        "                           activation=tf.keras.activations.relu, \n",
        "                           input_shape=(200, 200, 3)), \n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Conv2D(10, 3, 1),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1000, activation=tf.keras.activations.relu), \n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(29), \n",
        "    tf.keras.layers.Activation(tf.keras.activations.softmax, dtype=tf.float32)\n",
        "])\n",
        "model_3.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_3 = model_3.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_3\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJzpk07D-ajK",
        "outputId": "1407840c-284b-489b-9eb9-da26466fd175"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 104s 46ms/step - loss: 3.6921 - accuracy: 0.7242 - val_loss: 0.3754 - val_accuracy: 0.8768\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 99s 46ms/step - loss: 0.2827 - accuracy: 0.9057 - val_loss: 0.5054 - val_accuracy: 0.8525\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 102s 47ms/step - loss: 0.2063 - accuracy: 0.9340 - val_loss: 0.2305 - val_accuracy: 0.9249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_3N (model_3 with normalized input images)"
      ],
      "metadata": {
        "id": "N7uMHxwpEMoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3N = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1/255.),\n",
        "    tf.keras.layers.Conv2D(10, 3, 1,\n",
        "                           activation=tf.keras.activations.relu, \n",
        "                           input_shape=(200, 200, 3)), \n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Conv2D(10, 3, 1),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1000, activation=tf.keras.activations.relu), \n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(500, activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.Dense(29), \n",
        "    tf.keras.layers.Activation(tf.keras.activations.softmax, dtype=tf.float32)\n",
        "])\n",
        "model_3N.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_3N = model_3N.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_3N\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWG_zCheECl2",
        "outputId": "6e05399c-868a-495c-b4e2-0514ffee8656"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 103s 47ms/step - loss: 0.8671 - accuracy: 0.7200 - val_loss: 0.2470 - val_accuracy: 0.9074\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 102s 47ms/step - loss: 0.1750 - accuracy: 0.9390 - val_loss: 0.1792 - val_accuracy: 0.9373\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 100s 46ms/step - loss: 0.1090 - accuracy: 0.9631 - val_loss: 0.1339 - val_accuracy: 0.9550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_4 (small tweaks on model_3N)"
      ],
      "metadata": {
        "id": "963WNiOwC9rL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    tf.keras.layers.Conv2D(10, 3, 1,\n",
        "                           activation=tf.keras.activations.relu, \n",
        "                           input_shape=(200, 200, 3)), \n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Conv2D(10, 3, 1, \n",
        "                           activation=tf.keras.activations.relu),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1000, activation=tf.keras.activations.relu), \n",
        "    tf.keras.layers.Dense(29), \n",
        "    tf.keras.layers.Activation(tf.keras.activations.softmax, dtype=tf.float32)\n",
        "])\n",
        "model_4.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_4 = model_4.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_4\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYvqfCPoFUSA",
        "outputId": "d3e68e96-79cf-4be1-ee48-0225966bb651"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 100s 45ms/step - loss: 0.6740 - accuracy: 0.7922 - val_loss: 0.1517 - val_accuracy: 0.9501\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 101s 46ms/step - loss: 0.0896 - accuracy: 0.9704 - val_loss: 0.0843 - val_accuracy: 0.9740\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 99s 45ms/step - loss: 0.0583 - accuracy: 0.9816 - val_loss: 0.1004 - val_accuracy: 0.9671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_5(completely different from previous models but using transfer learning)"
      ],
      "metadata": {
        "id": "hZ9PEvrxPg4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mixed_precision.set_global_policy(policy=\"float32\")"
      ],
      "metadata": {
        "id": "cifMbCHTRsTR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(False)\n",
        "base_model.trainable=False\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(200, 200, 3))\n",
        "x = base_model(inputs)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(29)(x)\n",
        "outputs = tf.keras.layers.Activation(tf.keras.activations.softmax)(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_5.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_5 = model_5.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_5\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fo9SHIVZQF3L",
        "outputId": "1c790915-b7f1-4d2e-da2e-c30d0296dfbd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 140s 61ms/step - loss: 0.3863 - accuracy: 0.9354 - val_loss: 0.0840 - val_accuracy: 0.9890\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 129s 59ms/step - loss: 0.0718 - accuracy: 0.9899 - val_loss: 0.0363 - val_accuracy: 0.9945\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 133s 61ms/step - loss: 0.0387 - accuracy: 0.9946 - val_loss: 0.0202 - val_accuracy: 0.9970\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_6(completely different from previous models but using transfer learning)"
      ],
      "metadata": {
        "id": "ogywN6N0UHyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.ResNet50V2(False)\n",
        "base_model.trainable=False\n",
        "\n",
        "\n",
        "inputs= tf.keras.layers.Input(shape=(200, 200, 3))\n",
        "x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
        "x = base_model(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(29)(x)\n",
        "outputs = tf.keras.layers.Activation(tf.keras.activations.softmax)(x)\n",
        "model_6 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_6.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_6 = model_6.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_6\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zx0WAh8UchR",
        "outputId": "24895f6c-265a-4056-cef1-35e84ad0397e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "2175/2175 [==============================] - 201s 91ms/step - loss: 0.2927 - accuracy: 0.9387 - val_loss: 0.0691 - val_accuracy: 0.9878\n",
            "Epoch 2/3\n",
            "2175/2175 [==============================] - 197s 90ms/step - loss: 0.0505 - accuracy: 0.9919 - val_loss: 0.0322 - val_accuracy: 0.9940\n",
            "Epoch 3/3\n",
            "2175/2175 [==============================] - 196s 90ms/step - loss: 0.0248 - accuracy: 0.9962 - val_loss: 0.0198 - val_accuracy: 0.9954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable=True\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPe66F57Sc1r",
        "outputId": "07e25bc8-5e3e-4d66-8b09-79cecac785ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_3 True\n",
            "1 conv1_pad True\n",
            "2 conv1_conv True\n",
            "3 pool1_pad True\n",
            "4 pool1_pool True\n",
            "5 conv2_block1_preact_bn True\n",
            "6 conv2_block1_preact_relu True\n",
            "7 conv2_block1_1_conv True\n",
            "8 conv2_block1_1_bn True\n",
            "9 conv2_block1_1_relu True\n",
            "10 conv2_block1_2_pad True\n",
            "11 conv2_block1_2_conv True\n",
            "12 conv2_block1_2_bn True\n",
            "13 conv2_block1_2_relu True\n",
            "14 conv2_block1_0_conv True\n",
            "15 conv2_block1_3_conv True\n",
            "16 conv2_block1_out True\n",
            "17 conv2_block2_preact_bn True\n",
            "18 conv2_block2_preact_relu True\n",
            "19 conv2_block2_1_conv True\n",
            "20 conv2_block2_1_bn True\n",
            "21 conv2_block2_1_relu True\n",
            "22 conv2_block2_2_pad True\n",
            "23 conv2_block2_2_conv True\n",
            "24 conv2_block2_2_bn True\n",
            "25 conv2_block2_2_relu True\n",
            "26 conv2_block2_3_conv True\n",
            "27 conv2_block2_out True\n",
            "28 conv2_block3_preact_bn True\n",
            "29 conv2_block3_preact_relu True\n",
            "30 conv2_block3_1_conv True\n",
            "31 conv2_block3_1_bn True\n",
            "32 conv2_block3_1_relu True\n",
            "33 conv2_block3_2_pad True\n",
            "34 conv2_block3_2_conv True\n",
            "35 conv2_block3_2_bn True\n",
            "36 conv2_block3_2_relu True\n",
            "37 max_pooling2d_6 True\n",
            "38 conv2_block3_3_conv True\n",
            "39 conv2_block3_out True\n",
            "40 conv3_block1_preact_bn True\n",
            "41 conv3_block1_preact_relu True\n",
            "42 conv3_block1_1_conv True\n",
            "43 conv3_block1_1_bn True\n",
            "44 conv3_block1_1_relu True\n",
            "45 conv3_block1_2_pad True\n",
            "46 conv3_block1_2_conv True\n",
            "47 conv3_block1_2_bn True\n",
            "48 conv3_block1_2_relu True\n",
            "49 conv3_block1_0_conv True\n",
            "50 conv3_block1_3_conv True\n",
            "51 conv3_block1_out True\n",
            "52 conv3_block2_preact_bn True\n",
            "53 conv3_block2_preact_relu True\n",
            "54 conv3_block2_1_conv True\n",
            "55 conv3_block2_1_bn True\n",
            "56 conv3_block2_1_relu True\n",
            "57 conv3_block2_2_pad True\n",
            "58 conv3_block2_2_conv True\n",
            "59 conv3_block2_2_bn True\n",
            "60 conv3_block2_2_relu True\n",
            "61 conv3_block2_3_conv True\n",
            "62 conv3_block2_out True\n",
            "63 conv3_block3_preact_bn True\n",
            "64 conv3_block3_preact_relu True\n",
            "65 conv3_block3_1_conv True\n",
            "66 conv3_block3_1_bn True\n",
            "67 conv3_block3_1_relu True\n",
            "68 conv3_block3_2_pad True\n",
            "69 conv3_block3_2_conv True\n",
            "70 conv3_block3_2_bn True\n",
            "71 conv3_block3_2_relu True\n",
            "72 conv3_block3_3_conv True\n",
            "73 conv3_block3_out True\n",
            "74 conv3_block4_preact_bn True\n",
            "75 conv3_block4_preact_relu True\n",
            "76 conv3_block4_1_conv True\n",
            "77 conv3_block4_1_bn True\n",
            "78 conv3_block4_1_relu True\n",
            "79 conv3_block4_2_pad True\n",
            "80 conv3_block4_2_conv True\n",
            "81 conv3_block4_2_bn True\n",
            "82 conv3_block4_2_relu True\n",
            "83 max_pooling2d_7 True\n",
            "84 conv3_block4_3_conv True\n",
            "85 conv3_block4_out True\n",
            "86 conv4_block1_preact_bn True\n",
            "87 conv4_block1_preact_relu True\n",
            "88 conv4_block1_1_conv True\n",
            "89 conv4_block1_1_bn True\n",
            "90 conv4_block1_1_relu True\n",
            "91 conv4_block1_2_pad True\n",
            "92 conv4_block1_2_conv True\n",
            "93 conv4_block1_2_bn True\n",
            "94 conv4_block1_2_relu True\n",
            "95 conv4_block1_0_conv True\n",
            "96 conv4_block1_3_conv True\n",
            "97 conv4_block1_out True\n",
            "98 conv4_block2_preact_bn True\n",
            "99 conv4_block2_preact_relu True\n",
            "100 conv4_block2_1_conv True\n",
            "101 conv4_block2_1_bn True\n",
            "102 conv4_block2_1_relu True\n",
            "103 conv4_block2_2_pad True\n",
            "104 conv4_block2_2_conv True\n",
            "105 conv4_block2_2_bn True\n",
            "106 conv4_block2_2_relu True\n",
            "107 conv4_block2_3_conv True\n",
            "108 conv4_block2_out True\n",
            "109 conv4_block3_preact_bn True\n",
            "110 conv4_block3_preact_relu True\n",
            "111 conv4_block3_1_conv True\n",
            "112 conv4_block3_1_bn True\n",
            "113 conv4_block3_1_relu True\n",
            "114 conv4_block3_2_pad True\n",
            "115 conv4_block3_2_conv True\n",
            "116 conv4_block3_2_bn True\n",
            "117 conv4_block3_2_relu True\n",
            "118 conv4_block3_3_conv True\n",
            "119 conv4_block3_out True\n",
            "120 conv4_block4_preact_bn True\n",
            "121 conv4_block4_preact_relu True\n",
            "122 conv4_block4_1_conv True\n",
            "123 conv4_block4_1_bn True\n",
            "124 conv4_block4_1_relu True\n",
            "125 conv4_block4_2_pad True\n",
            "126 conv4_block4_2_conv True\n",
            "127 conv4_block4_2_bn True\n",
            "128 conv4_block4_2_relu True\n",
            "129 conv4_block4_3_conv True\n",
            "130 conv4_block4_out True\n",
            "131 conv4_block5_preact_bn True\n",
            "132 conv4_block5_preact_relu True\n",
            "133 conv4_block5_1_conv True\n",
            "134 conv4_block5_1_bn True\n",
            "135 conv4_block5_1_relu True\n",
            "136 conv4_block5_2_pad True\n",
            "137 conv4_block5_2_conv True\n",
            "138 conv4_block5_2_bn True\n",
            "139 conv4_block5_2_relu True\n",
            "140 conv4_block5_3_conv True\n",
            "141 conv4_block5_out True\n",
            "142 conv4_block6_preact_bn True\n",
            "143 conv4_block6_preact_relu True\n",
            "144 conv4_block6_1_conv True\n",
            "145 conv4_block6_1_bn True\n",
            "146 conv4_block6_1_relu True\n",
            "147 conv4_block6_2_pad True\n",
            "148 conv4_block6_2_conv True\n",
            "149 conv4_block6_2_bn True\n",
            "150 conv4_block6_2_relu True\n",
            "151 max_pooling2d_8 True\n",
            "152 conv4_block6_3_conv True\n",
            "153 conv4_block6_out True\n",
            "154 conv5_block1_preact_bn True\n",
            "155 conv5_block1_preact_relu True\n",
            "156 conv5_block1_1_conv True\n",
            "157 conv5_block1_1_bn True\n",
            "158 conv5_block1_1_relu True\n",
            "159 conv5_block1_2_pad True\n",
            "160 conv5_block1_2_conv True\n",
            "161 conv5_block1_2_bn True\n",
            "162 conv5_block1_2_relu True\n",
            "163 conv5_block1_0_conv True\n",
            "164 conv5_block1_3_conv True\n",
            "165 conv5_block1_out True\n",
            "166 conv5_block2_preact_bn True\n",
            "167 conv5_block2_preact_relu True\n",
            "168 conv5_block2_1_conv True\n",
            "169 conv5_block2_1_bn True\n",
            "170 conv5_block2_1_relu True\n",
            "171 conv5_block2_2_pad True\n",
            "172 conv5_block2_2_conv True\n",
            "173 conv5_block2_2_bn True\n",
            "174 conv5_block2_2_relu True\n",
            "175 conv5_block2_3_conv True\n",
            "176 conv5_block2_out True\n",
            "177 conv5_block3_preact_bn True\n",
            "178 conv5_block3_preact_relu True\n",
            "179 conv5_block3_1_conv True\n",
            "180 conv5_block3_1_bn True\n",
            "181 conv5_block3_1_relu True\n",
            "182 conv5_block3_2_pad True\n",
            "183 conv5_block3_2_conv True\n",
            "184 conv5_block3_2_bn True\n",
            "185 conv5_block3_2_relu True\n",
            "186 conv5_block3_3_conv True\n",
            "187 conv5_block3_out True\n",
            "188 post_bn True\n",
            "189 post_relu True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_7(finetuning model_6)"
      ],
      "metadata": {
        "id": "tij6pLWJVjwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model_6, \"model_6\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9hf9SE9WFx-",
        "outputId": "02604a97-5682-49f4-837c-e7b89be73931"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_7 = tf.keras.models.load_model(\"model_6\")\n",
        "print(model_6.evaluate(test_data))\n",
        "print(model_7.evaluate(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ablHwd0BX7m5",
        "outputId": "b543ab33-7046-4d7d-cad2-103d2248b5f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "544/544 [==============================] - 47s 87ms/step - loss: 0.0215 - accuracy: 0.9957\n",
            "[0.021491598337888718, 0.9956896305084229]\n",
            "544/544 [==============================] - 48s 86ms/step - loss: 0.0215 - accuracy: 0.9957\n",
            "[0.021491607651114464, 0.9956896305084229]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-10]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model_7.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        ")"
      ],
      "metadata": {
        "id": "NsRL_aXSVfKn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_7 = model_5.fit(\n",
        "    train_data, \n",
        "    epochs=5, \n",
        "    steps_per_epoch=len(train_data), \n",
        "    initial_epoch=2,\n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_7\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAGhlv9QT92s",
        "outputId": "fc9b6e18-8c65-4ad7-e2cb-fcfc3a41a91c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5\n",
            "2175/2175 [==============================] - 133s 61ms/step - loss: 0.0257 - accuracy: 0.9961 - val_loss: 0.0141 - val_accuracy: 0.9977\n",
            "Epoch 4/5\n",
            "2175/2175 [==============================] - 133s 61ms/step - loss: 0.0185 - accuracy: 0.9976 - val_loss: 0.0108 - val_accuracy: 0.9977\n",
            "Epoch 5/5\n",
            "2175/2175 [==============================] - 133s 61ms/step - loss: 0.0148 - accuracy: 0.9976 - val_loss: 0.0072 - val_accuracy: 0.9982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_8 (same as model model_5 but with 50% less training data)"
      ],
      "metadata": {
        "id": "31-qne3bdiKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(False)\n",
        "base_model.trainable=False\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(200, 200, 3))\n",
        "x = base_model(inputs)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(29)(x)\n",
        "outputs = tf.keras.layers.Activation(tf.keras.activations.softmax)(x)\n",
        "model_8 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_8.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_8 = model_8.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=int(0.5 *len(train_data)), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_8\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2Ld0BCLd0wH",
        "outputId": "e8c85416-834c-4710-9172-287db72b967c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1087/1087 [==============================] - 79s 67ms/step - loss: 0.6234 - accuracy: 0.8934 - val_loss: 0.1760 - val_accuracy: 0.9773\n",
            "Epoch 2/3\n",
            "1087/1087 [==============================] - 68s 63ms/step - loss: 0.1500 - accuracy: 0.9793 - val_loss: 0.0839 - val_accuracy: 0.9901\n",
            "Epoch 3/3\n",
            "   1/1087 [..............................] - ETA: 57s - loss: 0.1902 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3261 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1087/1087 [==============================] - 10s 9ms/step - loss: 0.1902 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_9(same as model_5 but with 25% of training data)"
      ],
      "metadata": {
        "id": "p8qb34HmeGKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(False)\n",
        "base_model.trainable=False\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(200, 200, 3))\n",
        "x = base_model(inputs)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(29)(x)\n",
        "outputs = tf.keras.layers.Activation(tf.keras.activations.softmax)(x)\n",
        "model_9 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_9.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_9 = model_9.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=int(0.25 *len(train_data)), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_9\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9NlYLYUeavq",
        "outputId": "da837327-c4ae-41f1-bc70-8e1f5d263201"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "543/543 [==============================] - 48s 78ms/step - loss: 0.9583 - accuracy: 0.8244 - val_loss: 0.3423 - val_accuracy: 0.9552\n",
            "Epoch 2/3\n",
            "543/543 [==============================] - 41s 75ms/step - loss: 0.2797 - accuracy: 0.9608 - val_loss: 0.1728 - val_accuracy: 0.9786\n",
            "Epoch 3/3\n",
            "543/543 [==============================] - 38s 69ms/step - loss: 0.1721 - accuracy: 0.9746 - val_loss: 0.1152 - val_accuracy: 0.9844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_10 (same as model_5 but with 10% of training data)"
      ],
      "metadata": {
        "id": "gcqz6UCFg0oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(False)\n",
        "base_model.trainable=False\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(200, 200, 3))\n",
        "x = base_model(inputs)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(29)(x)\n",
        "outputs = tf.keras.layers.Activation(tf.keras.activations.softmax)(x)\n",
        "model_10 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_10.compile(\n",
        "    loss=\"categorical_crossentropy\", \n",
        "    metrics=[\"accuracy\"], \n",
        "    optimizer=tf.keras.optimizers.Adam()\n",
        ")\n",
        "history_10 = model_10.fit(\n",
        "    train_data, \n",
        "    epochs=3, \n",
        "    steps_per_epoch=int(0.10 *len(train_data)), \n",
        "    validation_data=test_data, \n",
        "    validation_steps=int(0.25 * len(test_data)), \n",
        "    callbacks=[tf.keras.callbacks.TensorBoard(\"tensorboard/model_10\")]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PZ5u-wsgyKr",
        "outputId": "62d1329c-ee7a-4a68-f013-37edc9b99050"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "217/217 [==============================] - 27s 95ms/step - loss: 1.5997 - accuracy: 0.6770 - val_loss: 0.7651 - val_accuracy: 0.8902\n",
            "Epoch 2/3\n",
            "217/217 [==============================] - 22s 103ms/step - loss: 0.6100 - accuracy: 0.9119 - val_loss: 0.4208 - val_accuracy: 0.9416\n",
            "Epoch 3/3\n",
            "217/217 [==============================] - 22s 104ms/step - loss: 0.3959 - accuracy: 0.9450 - val_loss: 0.2960 - val_accuracy: 0.9589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing all the models that we have built with the test data"
      ],
      "metadata": {
        "id": "C2YXLeN2fOTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "lf5e7dvhfWOh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model_0, \"/content/drive/MyDrive/Project_signlanguage/model_0\")"
      ],
      "metadata": {
        "id": "1bOOYWtI1JzQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model_1, \"/content/drive/MyDrive/Project_signlanguage/model_1\")\n",
        "tf.keras.models.save_model(model_2_1, \"/content/drive/MyDrive/Project_signlanguage/model_2_1\")\n",
        "tf.keras.models.save_model(model_2_2, \"/content/drive/MyDrive/Project_signlanguage/model_2_2\")\n",
        "tf.keras.models.save_model(model_2_3, \"/content/drive/MyDrive/Project_signlanguage/model_2_3\")"
      ],
      "metadata": {
        "id": "6Mp0oejG1Jwh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model_3, \"/content/drive/MyDrive/Project_signlanguage/model_3\")\n",
        "tf.keras.models.save_model(model_3N, \"/content/drive/MyDrive/Project_signlanguage/model_3N\")\n",
        "tf.keras.models.save_model(model_4, \"/content/drive/MyDrive/Project_signlanguage/model_4\")\n",
        "tf.keras.models.save_model(model_5, \"/content/drive/MyDrive/Project_signlanguage/model_5\")"
      ],
      "metadata": {
        "id": "JY5C5syV1Jt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model_6, \"/content/drive/MyDrive/Project_signlanguage/model_6\")\n",
        "tf.keras.models.save_model(model_7, \"/content/drive/MyDrive/Project_signlanguage/model_7\")\n",
        "tf.keras.models.save_model(model_8, \"/content/drive/MyDrive/Project_signlanguage/model_8\")\n",
        "tf.keras.models.save_model(model_9, \"/content/drive/MyDrive/Project_signlanguage/model_9\")\n",
        "tf.keras.models.save_model(model_10, \"/content/drive/MyDrive/Project_signlanguage/model_10\")"
      ],
      "metadata": {
        "id": "mmQg40341JqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir ./tensorboard \\\n",
        "  --name \"sign language project experiments\" \\\n",
        "  --description \"A series of different experiment\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NC4a544OcUSw",
        "outputId": "6a33fbba-1636-4406-a871-400797c1007b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "./tensorboard\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=373649185512-8v619h5kft38l4456nm2dj4ubeqsrvh6.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&state=okhuq4acbJkLzreb1r3fnSRp4PnTBT&prompt=consent&access_type=offline\n",
            "Enter the authorization code: 4/1AWgavde_3lgwVF8KSJRrGA4kgMUt1PJMD48Zu5es24cHegClZ-jibGrXmIU\n",
            "\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/kMD9Em32R7qbXqUZRrfWMQ/\n",
            "\n",
            "\u001b[1m[2023-01-22T18:50:34]\u001b[0m Started scanning logdir.\n",
            "E0122 18:50:35.791773 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:36.804176 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:37.790621 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:39.791455 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:42.867729 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:44.844136 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:46.806197 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:47.862064 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:49.796445 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:51.811715 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:53.848072 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:54.807289 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:56.839010 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:50:58.804923 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:51:00.838894 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:51:01.833375 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:51:03.832369 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E0122 18:51:05.821238 140349720271936 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "\u001b[1m[2023-01-22T18:51:06]\u001b[0m Total uploaded: 510 scalars, 0 tensors, 14 binary objects (4.9 MB)\n",
            "\u001b[90mTotal skipped: 18 binary objects (5.2 MB)\n",
            "\u001b[0m\u001b[1m[2023-01-22T18:51:06]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/kMD9Em32R7qbXqUZRrfWMQ/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-3Zig1dh1Os"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}